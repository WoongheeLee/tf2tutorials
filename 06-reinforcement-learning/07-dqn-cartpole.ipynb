{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human-Level Control Through Deep Reinforcement Learning\n",
    "* DQN\n",
    "* nature 2015\n",
    "* 구글 딥마인드 연구\n",
    "* DQN 논문 리뷰 영상 https://www.youtube.com/watch?v=eJXQKEtPvhY 의 슬라이드 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "* input: 게임화면을 state로 주고, 게임 점수는 reward로 줌\n",
    "* output: reward 기대값 최대가 되는 policy 찾기\n",
    "* 구체적인 state를 주지않고, 게임 pixel만 줘서 사람보다 게임 잘하는 agent 를 만듦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 사전 지식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning\n",
    "* TD target은 우리가 학습시키려는 policy $\\pi$에서 greedy 하게 뽑고\n",
    "\n",
    "$$\n",
    "\\pi (S_{t+1}) = \\arg \\max_{a'} Q(S_{t+1}, a')\n",
    "$$\n",
    "\n",
    "* 현재 value는 behaviour policy $\\mu$ (이놈은 우리가 배우고자하는 policy. 예를 들어 사람의 행동일 수도 있고, 좀 더 성능이 나은 agent의 policy일 수도 있음) 에서 $\\epsilon$-greedy 하게 뽑음\n",
    "\n",
    "$$Q(S,A) \\leftarrow Q(S,A) + \\alpha \\big( R + \\gamma \\max_{a'} Q(S',a') - Q(S,A) \\big)$$\n",
    "\n",
    "(Q-learning control은 최적 action-value function 으로 수렴한다는 것이 증명되어 있음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Function Approximation (by SGD)\n",
    "* Goal: true value function $v_\\pi (s)$ 가 있다고 할 때, 이걸 바로 구할 수 없으니깐 학습시킬 수 있는 parameter $\\mathbf{w}$ 를 써서, value function $\\hat{v}(s,\\mathbf{w})$ 를 사용해서 true value function 에 근사시키자. 이 때 MSE 를 써서 근사시킨다.\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w}) = \\mathbb{E}_\\pi \\big[ (v_\\pi (S) - \\hat{v}(S, \\mathbf{w}))^2 \\big]\n",
    "$$\n",
    "\n",
    "* GD로 local minimum 찾으려면\n",
    "\n",
    "\\begin{align}\n",
    "\\Delta \\mathbf{w} & = - {1 \\over 2} \\alpha \\nabla_w J(w)\\\\\n",
    "& = \\alpha \\mathbb{E}_\\pi [ (v_\\pi (S) - \\hat(v) (S, w))\\nabla_w \\hat{v} (S, w) ]\n",
    "\\end{align}\n",
    "\n",
    "(위에 있는 J(w) 첫 행에 그대로 대입, 알파는 미분할 놈 아니라 앞으로 나오고, V(s)도 w없어서 사라지고 둘째 줄 처럼 미분 결과 나옴)\n",
    "\n",
    "* 위 식에서 샘플링하면 expectation 사라짐 -> SGD\n",
    "\n",
    "$$\n",
    "\\Delta w = \\alpha (v_\\pi (S) - \\hat{v} (S, w)) \\nabla_w \\hat{v}(S,w)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental Prediction Algorithms\n",
    "* 위 w 업뎃 방법은 oracle만 아는 $v_\\pi (s)$ 를 우리도 안다고 생각하고 업뎃해야하는데\n",
    "* 현실 세계에서는 그걸 모름\n",
    "* 그래서 걍 $v_\\pi(s)$ 자리에 다가 관측한 리턴 $G_t$ 를 넣으면 됨. 즉,\n",
    "  * MC 라면 target 은 return $G_t$\n",
    "  \n",
    "  $$\n",
    "  \\Delta w = \\alpha (G_t - \\hat{v} (S_t, w)) \\nabla_w \\hat{v}(S_t, w)\n",
    "  $$\n",
    "  \n",
    "  * TD(0) 이라면 TD target $R_{t+1} + \\gamma \\hat{v} (S_{t+1}, w)$ 적용\n",
    "  \n",
    "  $$\n",
    "  \\Delta w = \\alpha (R_{t+1} + \\gamma \\hat{v} (S_{t+1}, w) - \\hat{v} (S_t, w))\\nabla_w \\hat{v} (S_t, w)\n",
    "  $$\n",
    "  \n",
    "  * TD($\\lambda$)는 $\\lambda$-return $G_t^\\lambda$ 대입하면 됨\n",
    "  \n",
    "  $$\n",
    "  \\Delta w = \\alpha (G_t^\\lambda - \\hat{v}(S_t, w))\\nabla_w \\hat{v}(S_t,w)\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 학습 방법\n",
    "### Control\n",
    "$$\n",
    "L_i (\\theta_i) = \\mathbb{E}_{s,a,r,s'}\\sim U(D) \\Bigg[ \\Bigg( r + \\gamma \\max_{a'} Q(s',a';\\theta_i^-) - Q(s,a;\\theta_i) \\Bigg)^2 \\Bigg]\n",
    "$$\n",
    "\n",
    "* Behaviour policy 는 학습할 수 있도록 맨날 켜두고\n",
    "* Target policy 고정해두고 몇 iteration 마다 behaviour policy 복제해옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SGD 적용 하려면 위 control 식 미분\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta_i} L(\\theta_i) = \\mathbb{E}_{s,a,r,s'}\\Bigg[ \\Bigg( r + \\gamma \\max_{a'} Q(s',a';\\theta_i^-) - Q(s,a;\\theta_i) \\Bigg) \\nabla_{\\theta_i}Q(s,a;\\theta_i) \\Bigg]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q 함수는 CNN 모델로 function approximation 해버림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 안정성\n",
    "* RL에서 비선형 함수를 사용하면 학습 불안정 (발산하기도 함)\n",
    "* 왜냐면 observation 의 sequence에 있는 correlation 때문 (에피소드 끝날 때 까지 한 시쿼스 씩 가져다가 학습시키면 variance 커서 그런듯)\n",
    "$\\rightarrow$\n",
    "* 해결법\n",
    "  * experience replay\n",
    "  * target network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experience Replay\n",
    "* 시뮬레이션 돌리며 매 틱(time step) 마다 생성되는 transition 튜플 $(s_t, a_t, r_t, s_{t+1})$을 replay buffer에 저장해둠\n",
    "* replay buffer에서 uniform 하게 sampling 해서 minibatch 가져다가 학습시킴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Network\n",
    "(위에 요 내용)\n",
    "* Behaviour policy 는 학습할 수 있도록 맨날 켜두고\n",
    "* Target policy 고정해두고 몇 iteration 마다 behaviour policy 복제해옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo Code\n",
    "(원래 이미지 전처리하는 과정도 있어야하지만 그건 빼고 적음)\n",
    "* Replay memory D와 총 개수 N을 초기화 함\n",
    "* action-value function Q를 초기화 함 (뉴럴넷의 weight $\\theta$를 초기화)\n",
    "* target action-value function $\\hat{Q}$의 weight 초기화 $\\theta^- = \\theta$\n",
    "\n",
    "**For episode = 1, M do**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;시퀀스 $s_1 = \\{ x_1 \\}$와 preprocessed sequence $\\phi_1 = \\phi (s_1)$(이미지 처리용)을 초기화<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**For t=1, T do**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\epsilon$-greedy 로 action $a_t$ 선택<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;시뮬 돌려서 state $s_{t+1}$ 이랑 reward $r_t$ 얻음<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$s_{t+1} = s_t, a_t$ 얻음<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;transition $s_t, a_t, r_t, s_{t+1}$ 을 D에 넣음<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;D로부터 미니배치 샘플링함<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;target 정하는 과정<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) 만약 step j+1 에서 에피소드 끝났으면 $y_j = r_j$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) 아니면 $r_j + \\gamma \\max_{a'} \\hat{Q} (s_{t+1},a';\\theta^-)$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;뉴럴넷 $\\theta$를 $\\big( y_j - Q(s_{j+1},a_j;\\theta) \\big)^2$<br> 미분해서 업뎃<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;매 C번의 step 지나면 $\\hat{Q} = Q$ 로 복사해줌<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**End for**<br>\n",
    "**End for**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, optimizers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LR = 1e-3\n",
    "GAMMA = .95\n",
    "BUFFER_LIMIT = 100000\n",
    "BATCH_SIZE = 32\n",
    "EPISODES = 10000\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        총 길이가 제한이 있는 que만들기\n",
    "        '''\n",
    "        self.buffer = collections.deque(maxlen=BUFFER_LIMIT)\n",
    "        \n",
    "    def put(self, transition):\n",
    "        '''\n",
    "        args:\n",
    "            transitions: s, a, r, s', done(종료 step인지 아닌지 확인용)\n",
    "        '''\n",
    "        self.buffer.append(transition)\n",
    "        \n",
    "    def sample(self, n):\n",
    "        '''\n",
    "        args:\n",
    "            샘플링할 개수 n\n",
    "        return:\n",
    "            replay buffer에 저장된 transition 중 n개 random sampling\n",
    "        '''\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "        for transition in mini_batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append(a)\n",
    "            r_lst.append(r)\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append(done_mask)\n",
    "            \n",
    "        return np.array(s_lst),np.array(a_lst),np.array(r_lst),np.array(s_prime_lst),np.array(done_mask_lst)\n",
    "    \n",
    "    def size(self):\n",
    "        '''\n",
    "        replay buffer 현재 크기 확인용\n",
    "        '''\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet(models.Model):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        3층 layer로 간단히 구현\n",
    "        최종 layer는 value (real value 범위) 를 출력해야 하므로 activation function 없음\n",
    "        '''\n",
    "        super(Qnet, self).__init__()\n",
    "        self.qnet = models.Sequential([\n",
    "            layers.Dense(128, activation=tf.nn.relu),\n",
    "            layers.Dense(128, activation=tf.nn.relu),\n",
    "            layers.Dense(env.action_space.n)\n",
    "        ])\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        '''\n",
    "        args:\n",
    "            state\n",
    "        return:\n",
    "            value (given s, a지만 a는 명시적으로 주지 않음)\n",
    "        '''\n",
    "        x = self.qnet(x, training=training)\n",
    "        return x\n",
    "    \n",
    "    def sample_action(self, obs, epsilon):\n",
    "        '''\n",
    "        args:\n",
    "            state\n",
    "        return:\n",
    "            epsilon greedy로 action 선택\n",
    "        '''\n",
    "        e = random.random()\n",
    "        if e < epsilon:\n",
    "            return env.action_space.sample()\n",
    "        else:\n",
    "            x = tf.squeeze(self.call(obs))\n",
    "            return tf.argmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=LR)\n",
    "loss_func = losses.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(q, q_target, memory):\n",
    "    '''\n",
    "    args:\n",
    "        q: behaviour policy = mu\n",
    "        q_target: target policy = pi\n",
    "        memory: replay memory\n",
    "    return:\n",
    "        None\n",
    "        모델 학습시킴\n",
    "    '''\n",
    "    for i in range(EPOCHS):\n",
    "        s,a,r,s_prime,done_mask = memory.sample(BATCH_SIZE)\n",
    "\n",
    "        with tf.GradientTape() as t:\n",
    "            # state에 따른 value 뽑아냄\n",
    "            q_out = q(s, training=True)\n",
    "            q_out = tf.multiply(q_out, a)\n",
    "            # 그 중에서 action 취한 value만 뽑아냄\n",
    "            q_out = tf.reduce_max(q_out, axis=-1)\n",
    "\n",
    "            # target, s'에 대한 value 계산\n",
    "            max_q_prime = q_target(s_prime)\n",
    "            # 그 중에서 max 인 value만 뽑아냄\n",
    "            max_q_prime = tf.reduce_max(max_q_prime, axis=-1)\n",
    "\n",
    "            target = r + GAMMA * max_q_prime * done_mask\n",
    "            loss = loss_func(q_out, target)\n",
    "\n",
    "        grads = t.gradient(loss, q.trainable_variables)\n",
    "        optimizer.apply_gradients(list(zip(grads, q.trainable_variables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsilon: 1 부터 시작해서 최종 EPISODES 까지 선형적으로 .1이 되도록 줄어듦\n",
    "f = lambda x: max(1 - 1/EPISODES*x, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "q = Qnet()\n",
    "q_target = Qnet()\n",
    "memory = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_func(s):\n",
    "    return tf.expand_dims(tf.cast(s,dtype=tf.float32), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# theta로 부터 theta- 초기화 때 한 번만 복사할 flag\n",
    "copy = True\n",
    "\n",
    "r_list = []\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    epsilon = f(e)\n",
    "    s = env.reset()\n",
    "    s = state_func(s)\n",
    "    done = False\n",
    "    \n",
    "    r_sum = 0.\n",
    "    \n",
    "    while not done:\n",
    "        # 주어진 state로부터 action 구함\n",
    "        a = tf.squeeze(q.sample_action(s, epsilon))\n",
    "        \n",
    "        # (s,a) -> r, s' 구함\n",
    "        s_prime, r, done, _ = env.step(int(a))\n",
    "        done_mask = tf.zeros(1,) if done else tf.ones(1,)\n",
    "        r_sum += r\n",
    "        \n",
    "        # action 을 one-hot encoding 해서 transition 에 저장\n",
    "        _a = np.zeros((env.action_space.n,))\n",
    "        _a[int(a)] = 1.\n",
    "        a = tf.cast(_a, dtype=tf.float32)\n",
    "        r = tf.expand_dims(r,axis=0)\n",
    "        \n",
    "        # state -> one-hot encoding 해서 transition 에 저장\n",
    "        s_prime = state_func(s_prime)\n",
    "        \n",
    "        # (s, a, r, s') transition 을 저장해줌\n",
    "        memory.put((s, a, r, s_prime, done_mask))\n",
    "        \n",
    "        # 다음 state s' 가 이제 현재 s가 됨\n",
    "        s = s_prime.numpy()\n",
    "        \n",
    "        \n",
    "        # 에피소드 끝\n",
    "        if done: \n",
    "            r_list.append(r_sum)\n",
    "            break\n",
    "            \n",
    "        if copy:\n",
    "            q(memory.sample(1)[0])\n",
    "            q_target(memory.sample(1)[0])\n",
    "            q_target.set_weights(q.get_weights())\n",
    "            copy = False\n",
    "                        \n",
    "    # transition 몇 개 이상 모이면 학습\n",
    "    # 성공 경험이 있을 때 학습\n",
    "    if memory.size() > 2000 and np.sum(r_list) > 0:\n",
    "        train(q, q_target, memory)\n",
    "        \n",
    "    if e != 0 and e%20 == 0:\n",
    "        \n",
    "        # 가끔 behaviour 를 target에 복사해줌\n",
    "        q_target.set_weights(q.get_weights())\n",
    "        \n",
    "    ipd.clear_output(wait=True)\n",
    "    plt.figure(facecolor='w',figsize=(10,1))\n",
    "    plt.plot(r_list)\n",
    "    plt.title(f\"{e+1}/{EPISODES}, avg. r={np.sum(r_list[-100:])/100:.2f}, e={epsilon:.2f}\")\n",
    "    plt.show()\n",
    "        \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
