{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human-Level Control Through Deep Reinforcement Learning\n",
    "* DQN\n",
    "* nature 2015\n",
    "* 구글 딥마인드 연구\n",
    "* DQN 논문 리뷰 영상 https://www.youtube.com/watch?v=eJXQKEtPvhY 의 슬라이드 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "* input: 게임화면을 state로 주고, 게임 점수는 reward로 줌\n",
    "* output: reward 기대값 최대가 되는 policy 찾기\n",
    "* 구체적인 state를 주지않고, 게임 pixel만 줘서 사람보다 게임 잘하는 agent 를 만듦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 사전 지식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning\n",
    "* TD target은 우리가 학습시키려는 policy $\\pi$에서 greedy 하게 뽑고\n",
    "\n",
    "$$\n",
    "\\pi (S_{t+1}) = \\arg \\max_{a'} Q(S_{t+1}, a')\n",
    "$$\n",
    "\n",
    "* 현재 value는 behaviour policy $\\mu$ (이놈은 우리가 배우고자하는 policy. 예를 들어 사람의 행동일 수도 있고, 좀 더 성능이 나은 agent의 policy일 수도 있음) 에서 $\\epsilon$-greedy 하게 뽑음\n",
    "\n",
    "$$Q(S,A) \\leftarrow Q(S,A) + \\alpha \\big( R + \\gamma \\max_{a'} Q(S',a') - Q(S,A) \\big)$$\n",
    "\n",
    "(Q-learning control은 최적 action-value function 으로 수렴한다는 것이 증명되어 있음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Function Approximation (by SGD)\n",
    "* Goal: true value function $v_\\pi (s)$ 가 있다고 할 때, 이걸 바로 구할 수 없으니깐 학습시킬 수 있는 parameter $\\mathbf{w}$ 를 써서, value function $\\hat{v}(s,\\mathbf{w})$ 를 사용해서 true value function 에 근사시키자. 이 때 MSE 를 써서 근사시킨다.\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w}) = \\mathbb{E}_\\pi \\big[ (v_\\pi (S) - \\hat{v}(S, \\mathbf{w}))^2 \\big]\n",
    "$$\n",
    "\n",
    "* GD로 local minimum 찾으려면\n",
    "\n",
    "\\begin{align}\n",
    "\\Delta \\mathbf{w} & = - {1 \\over 2} \\alpha \\nabla_w J(w)\\\\\n",
    "& = \\alpha \\mathbb{E}_\\pi [ (v_\\pi (S) - \\hat(v) (S, w))\\nabla_w \\hat{v} (S, w) ]\n",
    "\\end{align}\n",
    "\n",
    "(위에 있는 J(w) 첫 행에 그대로 대입, 알파는 미분할 놈 아니라 앞으로 나오고, V(s)도 w없어서 사라지고 둘째 줄 처럼 미분 결과 나옴)\n",
    "\n",
    "* 위 식에서 샘플링하면 expectation 사라짐 -> SGD\n",
    "\n",
    "$$\n",
    "\\Delta w = \\alpha (v_\\pi (S) - \\hat{v} (S, w)) \\nabla_w \\hat{v}(S,w)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental Prediction Algorithms\n",
    "* 위 w 업뎃 방법은 oracle만 아는 $v_\\pi (s)$ 를 우리도 안다고 생각하고 업뎃해야하는데\n",
    "* 현실 세계에서는 그걸 모름\n",
    "* 그래서 걍 $v_\\pi(s)$ 자리에 다가 관측한 리턴 $G_t$ 를 넣으면 됨. 즉,\n",
    "  * MC 라면 target 은 return $G_t$\n",
    "  \n",
    "  $$\n",
    "  \\Delta w = \\alpha (G_t - \\hat{v} (S_t, w)) \\nabla_w \\hat{v}(S_t, w)\n",
    "  $$\n",
    "  \n",
    "  * TD(0) 이라면 TD target $R_{t+1} + \\gamma \\hat{v} (S_{t+1}, w)$ 적용\n",
    "  \n",
    "  $$\n",
    "  \\Delta w = \\alpha (R_{t+1} + \\gamma \\hat{v} (S_{t+1}, w) - \\hat{v} (S_t, w))\\nabla_w \\hat{v} (S_t, w)\n",
    "  $$\n",
    "  \n",
    "  * TD($\\lambda$)는 $\\lambda$-return $G_t^\\lambda$ 대입하면 됨\n",
    "  \n",
    "  $$\n",
    "  \\Delta w = \\alpha (G_t^\\lambda - \\hat{v}(S_t, w))\\nabla_w \\hat{v}(S_t,w)\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 학습 방법\n",
    "### Control\n",
    "$$\n",
    "L_i (\\theta_i) = \\mathbb{E}_{s,a,r,s'}\\sim U(D) \\Bigg[ \\Bigg( r + \\gamma \\max_{a'} Q(s',a';\\theta_i^-) - Q(s,a;\\theta_i) \\Bigg)^2 \\Bigg]\n",
    "$$\n",
    "\n",
    "* Behaviour policy 는 학습할 수 있도록 맨날 켜두고\n",
    "* Target policy 고정해두고 몇 iteration 마다 behaviour policy 복제해옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SGD 적용 하려면 위 control 식 미분\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta_i} L(\\theta_i) = \\mathbb{E}_{s,a,r,s'}\\Bigg[ \\Bigg( r + \\gamma \\max_{a'} Q(s',a';\\theta_i^-) - Q(s,a;\\theta_i) \\Bigg) \\nabla_{\\theta_i}Q(s,a;\\theta_i) \\Bigg]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Q 함수는 CNN 모델로 function approximation 해버림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 안정성\n",
    "* RL에서 비선형 함수를 사용하면 학습 불안정 (발산하기도 함)\n",
    "* 왜냐면 observation 의 sequence에 있는 correlation 때문 (에피소드 끝날 때 까지 한 시쿼스 씩 가져다가 학습시키면 variance 커서 그런듯)\n",
    "$\\rightarrow$\n",
    "* 해결법\n",
    "  * experience replay\n",
    "  * target network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experience Replay\n",
    "* 시뮬레이션 돌리며 매 틱(time step) 마다 생성되는 transition 튜플 $(s_t, a_t, r_t, s_{t+1})$을 replay buffer에 저장해둠\n",
    "* replay buffer에서 uniform 하게 sampling 해서 minibatch 가져다가 학습시킴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Network\n",
    "(위에 요 내용)\n",
    "* Behaviour policy 는 학습할 수 있도록 맨날 켜두고\n",
    "* Target policy 고정해두고 몇 iteration 마다 behaviour policy 복제해옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo Code\n",
    "(원래 이미지 전처리하는 과정도 있어야하지만 그건 빼고 적음)\n",
    "* Replay memory D와 총 개수 N을 초기화 함\n",
    "* action-value function Q를 초기화 함 (뉴럴넷의 weight $\\theta$를 초기화)\n",
    "* target action-value function $\\hat{Q}$의 weight 초기화 $\\theta^- = \\theta$\n",
    "\n",
    "**For episode = 1, M do**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;시퀀스 $s_1 = \\{ x_1 \\}$와 preprocessed sequence $\\phi_1 = \\phi (s_1)$(이미지 처리용)을 초기화<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**For t=1, T do**<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$\\epsilon$-greedy 로 action $a_t$ 선택<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;시뮬 돌려서 state $s_{t+1}$ 이랑 reward $r_t$ 얻음<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;$s_{t+1} = s_t, a_t$ 얻음<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;transition $s_t, a_t, r_t, s_{t+1}$ 을 D에 넣음<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;D로부터 미니배치 샘플링함<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;target 정하는 과정<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1) 만약 step j+1 에서 에피소드 끝났으면 $y_j = r_j$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2) 아니면 $r_j + \\gamma \\max_{a'} \\hat{Q} (s_{t+1},a';\\theta^-)$<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;뉴럴넷 $\\theta$를 $\\big( y_j - Q(s_{j+1},a_j;\\theta) \\big)^2$<br> 미분해서 업뎃<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;매 C번의 step 지나면 $\\hat{Q} = Q$ 로 복사해줌<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**End for**<br>\n",
    "**End for**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers, optimizers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LR = 1e-4\n",
    "GAMMA = .95\n",
    "BUFFER_LIMIT = 10000\n",
    "BATCH_SIZE = 32\n",
    "EPISODES = 10000\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        총 길이가 제한이 있는 que만들기\n",
    "        '''\n",
    "        self.buffer = collections.deque(maxlen=BUFFER_LIMIT)\n",
    "        \n",
    "    def put(self, transition):\n",
    "        '''\n",
    "        args:\n",
    "            transitions: s, a, r, s', done(종료 step인지 아닌지 확인용)\n",
    "        '''\n",
    "        self.buffer.append(transition)\n",
    "        \n",
    "    def sample(self, n):\n",
    "        '''\n",
    "        args:\n",
    "            샘플링할 개수 n\n",
    "        return:\n",
    "            replay buffer에 저장된 transition 중 n개 random sampling\n",
    "        '''\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "        for transition in mini_batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append(a)\n",
    "            r_lst.append(r)\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append(done_mask)\n",
    "            \n",
    "        return np.array(s_lst),np.array(a_lst),np.array(r_lst),np.array(s_prime_lst),np.array(done_mask_lst)\n",
    "    \n",
    "    def size(self):\n",
    "        '''\n",
    "        replay buffer 현재 크기 확인용\n",
    "        '''\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet(models.Model):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        3층 layer로 간단히 구현\n",
    "        최종 layer는 value (real value 범위) 를 출력해야 하므로 activation function 없음\n",
    "        '''\n",
    "        super(Qnet, self).__init__()\n",
    "        self.qnet = models.Sequential([\n",
    "            layers.Dense(128, activation=tf.nn.relu),\n",
    "            layers.Dense(128, activation=tf.nn.relu),\n",
    "            layers.Dense(env.action_space.n)\n",
    "        ])\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        '''\n",
    "        args:\n",
    "            state\n",
    "        return:\n",
    "            value (given s, a지만 a는 명시적으로 주지 않음)\n",
    "        '''\n",
    "        x = self.qnet(x, training=training)\n",
    "        return x\n",
    "    \n",
    "    def sample_action(self, obs, epsilon):\n",
    "        '''\n",
    "        args:\n",
    "            state\n",
    "        return:\n",
    "            epsilon greedy로 action 선택\n",
    "        '''\n",
    "        e = random.random()\n",
    "        if e < epsilon:\n",
    "            return env.action_space.sample()\n",
    "        else:\n",
    "            x = tf.squeeze(self.call(obs))\n",
    "            return tf.argmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=LR)\n",
    "loss_func = losses.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(q, q_target, memory):\n",
    "    '''\n",
    "    args:\n",
    "        q: behaviour policy = mu\n",
    "        q_target: target policy = pi\n",
    "        memory: replay memory\n",
    "    return:\n",
    "        None\n",
    "        모델 학습시킴\n",
    "    '''\n",
    "    for i in range(EPOCHS):\n",
    "        s,a,r,s_prime,done_mask = memory.sample(BATCH_SIZE)\n",
    "\n",
    "        with tf.GradientTape() as t:\n",
    "            # state에 따른 value 뽑아냄\n",
    "            q_out = q(s, training=True)\n",
    "            q_out = tf.multiply(q_out, a)\n",
    "            # 그 중에서 action 취한 value만 뽑아냄\n",
    "            q_out = tf.reduce_max(q_out, axis=-1)\n",
    "\n",
    "            # target, s'에 대한 value 계산\n",
    "            max_q_prime = q_target(s_prime)\n",
    "            # 그 중에서 max 인 value만 뽑아냄\n",
    "            max_q_prime = tf.reduce_max(max_q_prime, axis=-1)\n",
    "\n",
    "            target = r + GAMMA * max_q_prime * done_mask\n",
    "            loss = loss_func(q_out, target)\n",
    "\n",
    "        grads = t.gradient(loss, q.trainable_variables)\n",
    "        optimizer.apply_gradients(list(zip(grads, q.trainable_variables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epsilon: 1 부터 시작해서 최종 EPISODES 까지 선형적으로 .1이 되도록 줄어듦\n",
    "f = lambda x: max(.8 - 1/EPISODES*x, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "q = Qnet()\n",
    "q_target = Qnet()\n",
    "memory = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_func(s):\n",
    "    return tf.expand_dims(tf.cast(s,dtype=tf.float32), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# theta로 부터 theta- 초기화 때 한 번만 복사할 flag\n",
    "copy = True\n",
    "\n",
    "r_list = []\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    epsilon = f(e)\n",
    "    s = env.reset()\n",
    "    s = state_func(s)\n",
    "    done = False\n",
    "    \n",
    "    r_sum = 0.\n",
    "    \n",
    "    while not done:\n",
    "        # 주어진 state로부터 action 구함\n",
    "        a = tf.squeeze(q.sample_action(s, epsilon))\n",
    "        \n",
    "        # (s,a) -> r, s' 구함\n",
    "        s_prime, r, done, _ = env.step(int(a))\n",
    "        done_mask = tf.zeros(1,) if done else tf.ones(1,)\n",
    "        r_sum += r\n",
    "        \n",
    "        # action 을 one-hot encoding 해서 transition 에 저장\n",
    "        _a = np.zeros((env.action_space.n,))\n",
    "        _a[int(a)] = 1.\n",
    "        a = tf.cast(_a, dtype=tf.float32)\n",
    "        r = tf.expand_dims(r,axis=0)\n",
    "        \n",
    "        # state -> one-hot encoding 해서 transition 에 저장\n",
    "        s_prime = state_func(s_prime)\n",
    "        \n",
    "        # (s, a, r, s') transition 을 저장해줌\n",
    "        memory.put((s, a, r, s_prime, done_mask))\n",
    "        \n",
    "        # 다음 state s' 가 이제 현재 s가 됨\n",
    "        s = s_prime.numpy()\n",
    "        \n",
    "        \n",
    "        # 에피소드 끝\n",
    "        if done: \n",
    "            r_list.append(r_sum)\n",
    "            break\n",
    "            \n",
    "        if copy:\n",
    "            q(memory.sample(1)[0])\n",
    "            q_target(memory.sample(1)[0])\n",
    "            q_target.set_weights(q.get_weights())\n",
    "            copy = False\n",
    "                        \n",
    "    # transition 몇 개 이상 모이면 학습\n",
    "    if memory.size() > 2000:\n",
    "        train(q, q_target, memory)\n",
    "        \n",
    "    if e != 0 and e%20 == 0:\n",
    "        \n",
    "        # 가끔 behaviour 를 target에 복사해줌\n",
    "        q_target.set_weights(q.get_weights())\n",
    "        \n",
    "    ipd.clear_output(wait=True)\n",
    "    plt.figure(facecolor='w',figsize=(10,1))\n",
    "    plt.plot(r_list)\n",
    "    plt.title(f\"{e+1}/{EPISODES}, avg. r={np.sum(r_list[-100:])/100:.2f}, e={epsilon:.2f}\")\n",
    "    plt.show()\n",
    "        \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
