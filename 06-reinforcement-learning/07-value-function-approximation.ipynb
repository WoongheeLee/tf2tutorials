{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Function Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large-Scale Reinforcement Learning\n",
    "강화학습은 large problem 에 적용 가능. 예를 들면\n",
    "* 바둑: $10^{170}$ states\n",
    "* 헬리콥터: continuous state space\n",
    "\n",
    "prediction과 control 문제에 model-free 를 어떻게 적용할거냐?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Function Approximation\n",
    "* 이전까지는 value function 을 lookup table 을 썼음\n",
    "  * 모든 state s 는 $V(s)$ 에 입력\n",
    "  * 또는 모든 state-action 쌍 s, a를 $Q(s, a)$ 에 입력\n",
    "* 큰 MDP 문제:\n",
    "  * 너무 많은 states 또는 actions 을 메모리에 넣어야 함\n",
    "  * 각각의 states를 학습하기에 너무 느림\n",
    "* 큰 MDP 문제 해법:\n",
    "  * value function 을 function approximation 을 사용하여 추정\n",
    "\\begin{align}\n",
    "\\hat{v}(s,w) & \\approx v_\\pi(s)\\\\\n",
    "\\mbox{or } \\hat{q}(s,a,w) & \\approx q_\\pi (s,a)\n",
    "\\end{align}\n",
    "  * 관측한 state로부터 관측안한 state도 generalize\n",
    "  * MC 나 TD learning 으로 파라미터 w 업뎃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Function Approximator?\n",
    "미분 가능한 function approximator 고려하기로 함. 예를 들어\n",
    "* Linear combinations of features\n",
    "* Neural network\n",
    "* Decision tree\n",
    "* Nearest neighbor\n",
    "* Fourier / wavelet bases\n",
    "* $\\cdots$\n",
    "\n",
    "(위에 두 가지만 다룸)\n",
    "\n",
    "non-stationary, non-iid data에 적합한 학습 방법도 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "* $J(w)$ 가 $w$로 미분가능할 때\n",
    "* $J(w)$ 의 gradient는 다음과 같이 정의\n",
    "$$\n",
    "\\nabla_w J(w) = \n",
    "\\begin{pmatrix}\n",
    "{\\partial J(w) \\over \\partial w_1}\\\\\n",
    "\\cdots\\\\\n",
    "{\\partial J(w) \\over \\partial w_n}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "* $J(w)$의 local minimum 찾기 위해서\n",
    "* $w$를 그레디언트 방향으로 조정\n",
    "$$\n",
    "\\Delta w = - {1 \\over 2} \\alpha \\nabla_w J(w)\n",
    "$$\n",
    "여기서 $\\alpha$는 step-size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Function Approximation (by SGD)\n",
    "* Goal: true value function $v_\\pi (s)$ 가 있다고 할 때, 이걸 바로 구할 수 없으니깐 학습시킬 수 있는 parameter $\\mathbf{w}$ 를 써서, value function $\\hat{v}(s,\\mathbf{w})$ 를 사용해서 true value function 에 근사시키자. 이 때 MSE 를 써서 근사시킨다.\n",
    "\n",
    "$$\n",
    "J(\\mathbf{w}) = \\mathbb{E}_\\pi \\big[ (v_\\pi (S) - \\hat{v}(S, \\mathbf{w}))^2 \\big]\n",
    "$$\n",
    "\n",
    "* GD로 local minimum 찾으려면\n",
    "\n",
    "\\begin{align}\n",
    "\\Delta \\mathbf{w} & = - {1 \\over 2} \\alpha \\nabla_w J(w)\\\\\n",
    "& = \\alpha \\mathbb{E}_\\pi [ (v_\\pi (S) - \\hat(v) (S, w))\\nabla_w \\hat{v} (S, w) ]\n",
    "\\end{align}\n",
    "\n",
    "(위에 있는 J(w) 첫 행에 그대로 대입, 알파는 미분할 놈 아니라 앞으로 나오고, V(s)도 w없어서 사라지고 둘째 줄 처럼 미분 결과 나옴)\n",
    "\n",
    "* 위 식에서 샘플링하면 expectation 사라짐 -> SGD\n",
    "\n",
    "$$\n",
    "\\Delta w = \\alpha (v_\\pi (S) - \\hat{v} (S, w)) \\nabla_w \\hat{v}(S,w)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Vectors\n",
    "* feature vector을 사용해서 state를 나타내기\n",
    "$$\n",
    "x(S) =\n",
    "\\begin{pmatrix}\n",
    "x_1(S)\\\\\n",
    "\\cdots\\\\\n",
    "x_n(S)\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "* 그니깐 state 있으면 그걸 함수를 써서 벡터로 변환한다는 것임\n",
    "* 여기서 S는 frozenlake 같이 16개 중에 하나 state를 의미하는 것이 아니라 관측이 불명확 할 때도 사용 가능\n",
    "* 예를 들면\n",
    "  * 목적지와 로봇 사이의 거리\n",
    "  * 주식시장의 경향 (주가에 영향 미치는 모든 것을 관측할 수 없으므로)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Value Function Approximation\n",
    "* value function 을 feature와 linear combination 으로 나타낼 수 있음\n",
    "$$\n",
    "\\hat{v}(S,w) = x(S)^T w = \\sum_{j=1}^n x_j (S) w_j\n",
    "$$\n",
    "\n",
    "* 목적식은 파라미터 w에 제곱함수\n",
    "$$\n",
    "J(w) = \\mathbb{E}_\\pi \\big[ (v_\\pi (S) - x(S)^T w)^2 \\big]\n",
    "$$\n",
    "\n",
    "* SGD는 global optimum 에 수렴\n",
    "* update rule은 단순\n",
    "\\begin{align}\n",
    "\\nabla_w \\hat{v} (S,w) & = x(S)\\\\\n",
    "\\Delta w & = \\alpha(v_\\pi (S) - \\hat{v} (S, w))x(S)\n",
    "\\end{align}\n",
    "\n",
    "update = step-size x prediction error x feature value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Lookup Features\n",
    "* Table lookup 은 linear value function approximation 의 특이 케이스\n",
    "* Table lookup feature 사용하기\n",
    "$$\n",
    "x^{table}(S) =\n",
    "\\begin{pmatrix}\n",
    "\\mathbf{1}(S=s_1)\\\\\n",
    "\\cdots\\\\\n",
    "\\mathbf{1}(S=s_n)\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "* 파라미터 벡터 w 는 각각의 state에 대응해서 줌\n",
    "$$\n",
    "\\hat{v} (S, w) =\n",
    "\\begin{pmatrix}\n",
    "\\mathbf{1}(S=s_1)\\\\\n",
    "\\cdots\\\\\n",
    "\\mathbf{1}(S=s_n)\n",
    "\\end{pmatrix}\n",
    "\\cdot\n",
    "\\begin{pmatrix}\n",
    "w_1\\\\\n",
    "\\cdots\\\\\n",
    "w_n\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental Prediction Algorithms\n",
    "* 우리는 지금까지 supervisor (oracle. 모든 것을 다 아는 존재)가 true value function $v_\\pi (s)$를 준다고 생각했음\n",
    "* 근데 RL은 supervisor 같은거 없고, rewards가 있을 뿐임\n",
    "* 현실에서 $v_\\pi (s)$ 에 해당하는 놈을 타겟으로 빼줌\n",
    "  * MC 에서 target은 return $G_t$임\n",
    "  \n",
    "  $$\n",
    "  \\Delta w = \\alpha (G_t - \\hat{v} (S_t, w))\\nabla_w \\hat{v} (S_t, w)\n",
    "  $$\n",
    "  \n",
    "  * TD(0) 에서는 TD target $R_{t+1} + \\gamma \\hat{v} (S_{t+1}, w)$\n",
    "  \n",
    "  $$\n",
    "  \\Delta w = \\alpha (R_{t+1} + \\gamma \\hat{v} (S_{t+1} , w) - \\hat{v} (S_t, w)) \\nabla_w \\hat{v}(S_t, w)\n",
    "  $$\n",
    "  \n",
    "  * TD($\\lambda$)에서는 $\\lambda$-return $G_t^\\lambda$ 임\n",
    "  \n",
    "  $$\n",
    "  \\Delta w = \\alpha (G_t^\\lambda - \\hat{v} (S_t, w))\\nabla_w \\hat{v} (S_t, w)\n",
    "  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
