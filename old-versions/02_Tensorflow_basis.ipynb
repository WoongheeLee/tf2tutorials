{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저희는 텐서플로 2.0 버전을 기준으로 합니다. 이번 튜토리얼에서는 간략한 예제로 텐서플로의 큰 그림을 잡고자 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import models, layers, losses, metrics, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로는 두 가지 방식의 페러다임(?)을 지원합니다.\n",
    "1. 그래프를 먼저 구축 및 빌드(컴파일)하고 그 그래프에 입력을 주는 방식.\n",
    "2. 대략적인 형태만 만들고, 입력이 들어가게 되면 그래프가 구축되는 방식(컴파일 없음).\n",
    "\n",
    "저희는 2번을 볼 텐데요, tensorflow 1.x에서는 1번이 기본이었지만, 2.0에서는 2번이 기본이 되었습니다. 텐서플로는 이것을 eager execution이라고 부르는데요,\n",
    "그래프를 그리고 session.run() 해야만 결과를 얻던 기존의 방식과 다르게 바로바로 결과를 얻을 수 있는 방식을 의미합니다. 이것이 활성화되있는지 알고 싶다면 다음을 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.0에서는 default값이 true입니다.\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습용 MNIST 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 연습용으로 쓸 MNIST 데이터를 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets.mnist import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = trainset\n",
    "x_test, y_test = testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 간단히 데이터를 standardize하는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = 0, std = 0.5\n",
    "x_train = (x_train.astype(np.float32) - 128) / 256\n",
    "x_test = (x_test.astype(np.float32) - 128) / 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 빠르게 모델을 만들어 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저, 이미지를 벡터로 펼치고,\n",
    "# 128개의 hidden unit을 가지는 dense(fully connected) layer\n",
    "# 128개의 hidden unit을 가지는 dense(fully connected) layer\n",
    "# 10개의 hidden unit을 가지는 dense(fully connected) layer\n",
    "\n",
    "myfirstmodel = models.Sequential([\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=tf.nn.tanh),\n",
    "    layers.Dense(128, activation=tf.nn.tanh),\n",
    "    layers.Dense(10, activation=tf.nn.softmax),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금, 모델의 레이어를 구성했는데요, 모델을 구성했으면, 이제 모델을 빌드해야 합니다.\n",
    "\n",
    "빌드하는 방법은 두 가지가 있는데요.\n",
    "1. .build() 호출.\n",
    "2. .fit() 또는 .call() 호출.\n",
    "\n",
    "Keras에는 모델을 구성했다고 해서 모델이 완성되는 것이 아닙니다. .build()를 호출하거나, forward propagation을 한번 이상 호출하게 되면 모델이 비로소 빌드가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfirstmodel.build(input_shape=(None, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras에는 빌드된 그래프를 간략히 요약해서 볼 수 있는 summary() 메소드가 존재합니다. 이 메소드는 빌드된 모델에 대해서만 호출이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  1290      \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "myfirstmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로, model을 학습시킬때 이용할 optimizer와 criterion (loss 함수), metric을 정의합니다.\n",
    "\n",
    "여기서, categorical cross entropy는 두 가지가 있습니다.\n",
    "- CategoricalCrossentropy\n",
    "- SparseCategoricalCrossentropy\n",
    "\n",
    "Sparse가 붙은 애들은 y_true값으로 one-hot된 라벨을 주지 않고, 그냥 라벨 인코딩 상태로만 넘겨줘야 하며, Sparse가 아닌 애들을 one-hot된 y_true값을 넘겨줘야 합니다.\n",
    "y_preds는 둘 다 형태가 같습니다.\n",
    "\n",
    "Sparse는 accuracy에도 해당됩니다. (SpareseCategoricalAccuracy, CategoricalAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(learning_rate=1e-3)\n",
    "criterion = losses.SparseCategoricalCrossentropy()\n",
    "metric = metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 모델을 주어진 optimizer, criterion, metric으로 컴파일해 봅시다. 컴파일을 해야 fit()을 호출해서 모델을 학습시킬 수 있죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfirstmodel.compile(optimizer, loss=criterion, metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 준비가 끝났습니다. 이제 fit()을 호출해서 모델을 학습시킬 일만 남았습니다.\n",
    "\n",
    "저는 개인적으로 fit()을 호출해서 모델을 학습시키는 방법을 좋아하지 않습니다. 따라서, fit()을 호출해서 모델을 학습시키는 것은 이번 튜토리얼이 아마 마지막이 될 수도 있습니다.\n",
    "지금은 개략적인 tensorflow 2.0을 보여주는 것이기에 fit()을 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 1s 29us/sample - loss: 0.4081 - sparse_categorical_accuracy: 0.8813 - val_loss: 0.2329 - val_sparse_categorical_accuracy: 0.9329\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.2017 - sparse_categorical_accuracy: 0.9403 - val_loss: 0.1761 - val_sparse_categorical_accuracy: 0.9498\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.1450 - sparse_categorical_accuracy: 0.9560 - val_loss: 0.1324 - val_sparse_categorical_accuracy: 0.9618\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 1s 13us/sample - loss: 0.1118 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.1219 - val_sparse_categorical_accuracy: 0.9650\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.0938 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.1088 - val_sparse_categorical_accuracy: 0.9688\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 1s 16us/sample - loss: 0.0788 - sparse_categorical_accuracy: 0.9758 - val_loss: 0.1113 - val_sparse_categorical_accuracy: 0.9670\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 1s 17us/sample - loss: 0.0669 - sparse_categorical_accuracy: 0.9798 - val_loss: 0.1002 - val_sparse_categorical_accuracy: 0.9696\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 1s 16us/sample - loss: 0.0578 - sparse_categorical_accuracy: 0.9822 - val_loss: 0.0939 - val_sparse_categorical_accuracy: 0.9737\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.0511 - sparse_categorical_accuracy: 0.9842 - val_loss: 0.0915 - val_sparse_categorical_accuracy: 0.9734\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 1s 14us/sample - loss: 0.0428 - sparse_categorical_accuracy: 0.9871 - val_loss: 0.0977 - val_sparse_categorical_accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8b201b4e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfirstmodel.fit(x_train, y_train, validation_split=0.2, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 학습시켰으면, 테스트를 해봐야 겠죠? 그 메소드는 evaluate()입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09244314468353987, 0.9711]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfirstmodel.evaluate(x_test, y_test, batch_size=128, verbose=0)\n",
    "# loss, accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
