{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers, losses, metrics, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "ETA = 1e-3\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = tf.data.Dataset.from_tensor_slices(trainset).batch(BATCH_SIZE).shuffle(4096)\n",
    "testloader = tf.data.Dataset.from_tensor_slices(testset).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalNeuralNetwork(models.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.features = models.Sequential([\n",
    "            layers.Conv2D(16, (3, 3), strides=(1, 1), padding=\"SAME\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(tf.nn.leaky_relu),\n",
    "            \n",
    "            layers.Conv2D(32, (3, 3), strides=(1, 1), padding=\"SAME\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation(tf.nn.leaky_relu),\n",
    "        ])\n",
    "        \n",
    "        self.flatten = layers.Flatten()\n",
    "        \n",
    "        self.classifier = models.Sequential([\n",
    "            layers.Dense(32),\n",
    "            layers.Activation(tf.nn.leaky_relu),\n",
    "            layers.Dropout(0.5),\n",
    "            \n",
    "            layers.Dense(10),\n",
    "            layers.Activation(tf.nn.softmax)\n",
    "        ])\n",
    "        \n",
    "    def __call__(self, inputs, training=False):\n",
    "        x = self.features(inputs, training=training)\n",
    "        x = self.flatten(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvolutionalNeuralNetwork()\n",
    "criterion = losses.SparseCategoricalCrossentropy()\n",
    "optimizer = optimizers.Adam(learning_rate=ETA)\n",
    "\n",
    "train_loss_obj = metrics.SparseCategoricalCrossentropy()\n",
    "test_loss_obj = metrics.SparseCategoricalCrossentropy()\n",
    "\n",
    "train_acc_obj = metrics.SparseCategoricalAccuracy()\n",
    "test_acc_obj = metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, y):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        ps = model(x)\n",
    "        loss = criterion(y, ps)\n",
    "        \n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    train_loss_obj.update_state(y, ps)\n",
    "    train_acc_obj.update_state(y, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(x, y):\n",
    "    \n",
    "    ps = model(x)\n",
    "    loss = criterion(y, ps)\n",
    "    \n",
    "    test_loss_obj.update_state(y, ps)\n",
    "    test_acc_obj.update_state(y, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    for e in range(EPOCHS):\n",
    "        \n",
    "        for x, y in trainloader:\n",
    "            x = tf.cast(x, tf.float32)/256\n",
    "            x = tf.expand_dims(x, axis=-1)\n",
    "            train_step(x, y)\n",
    "            \n",
    "        for x, y in testloader:\n",
    "            x = tf.cast(x, tf.float32)/256\n",
    "            x = tf.expand_dims(x, axis=-1)\n",
    "            test_step(x, y)\n",
    "            \n",
    "        train_loss = train_loss_obj.result()\n",
    "        test_loss = test_loss_obj.result()\n",
    "        \n",
    "        train_acc = train_acc_obj.result()\n",
    "        test_acc = test_acc_obj.result()\n",
    "        \n",
    "        print(f\"Epochs {e+1}/{EPOCHS}, train loss: {train_loss:.8f}, train acc: {train_acc:.4f}, test loss: {test_loss:.8f}, test acc: {test_acc:.4f}\")\n",
    "        \n",
    "        train_loss_obj.reset_states()\n",
    "        test_loss_obj.reset_states()\n",
    "        train_acc_obj.reset_states()\n",
    "        test_acc_obj.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1/10, train loss: 0.20986743, train acc: 0.9387, test loss: 0.07227330, test acc: 0.9768\n",
      "Epochs 2/10, train loss: 0.06776577, train acc: 0.9795, test loss: 0.05704554, test acc: 0.9831\n",
      "Epochs 3/10, train loss: 0.04428998, train acc: 0.9866, test loss: 0.04793566, test acc: 0.9843\n",
      "Epochs 4/10, train loss: 0.03384862, train acc: 0.9893, test loss: 0.04617216, test acc: 0.9855\n",
      "Epochs 5/10, train loss: 0.02655715, train acc: 0.9916, test loss: 0.05465016, test acc: 0.9829\n",
      "Epochs 6/10, train loss: 0.01944853, train acc: 0.9935, test loss: 0.06646930, test acc: 0.9797\n",
      "Epochs 7/10, train loss: 0.01642764, train acc: 0.9947, test loss: 0.05588628, test acc: 0.9842\n",
      "Epochs 8/10, train loss: 0.01496342, train acc: 0.9949, test loss: 0.06000015, test acc: 0.9843\n",
      "Epochs 9/10, train loss: 0.01087986, train acc: 0.9963, test loss: 0.06420957, test acc: 0.9840\n",
      "Epochs 10/10, train loss: 0.00952641, train acc: 0.9970, test loss: 0.06586394, test acc: 0.9843\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (Tensorflow 2)",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
